{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 作业2-年收入判断\n",
    "\n",
    "## 项目描述\n",
    "二元分类是机器学习中最基础的问题之一，在这份教学中，你将学会如何实作一个线性二元分类器，来根据人们的个人资料，判断其年收入是否高于 50,000 美元。我们将以两种方法: logistic regression 与 generative model，来达成以上目的，你可以尝试了解、分析两者的设计理念及差别。\n",
    "实现二分类任务：\n",
    "* 个人收入是否超过50000元？\n",
    "\n",
    "## 数据集介绍\n",
    "这个资料集是由UCI Machine Learning Repository 的Census-Income (KDD) Data Set 经过一些处理而得来。为了方便训练，我们移除了一些不必要的资讯，并且稍微平衡了正负两种标记的比例。事实上在训练过程中，只有 X_train、Y_train 和 X_test 这三个经过处理的档案会被使用到，train.csv 和 test.csv 这两个原始资料档则可以提供你一些额外的资讯。\n",
    "* 已经去除不必要的属性。\n",
    "* 已经平衡正标和负标数据之间的比例。\n",
    "\n",
    "**特征格式**\n",
    "1. train.csv，test_no_label.csv。\n",
    "* 基于文本的原始数据\n",
    "* 去掉不必要的属性，平衡正负比例。\n",
    "2. X_train, Y_train, X_test(测试)\n",
    "* train.csv中的离散特征=>在X_train中onehot编码(学历、状态...)\n",
    "* train.csv中的连续特征 => 在X_train中保持不变(年龄、资本损失...)。\n",
    "* X_train, X_test : 每一行包含一个510-dim的特征，代表一个样本。\n",
    "* Y_train: label = 0 表示 \"<=50K\" 、 label = 1 表示 \" >50K \" 。\n",
    "\n",
    "## 项目要求\n",
    "1. 请动手编写 gradient descent 实现 logistic regression\n",
    "1. 请动手实现概率生成模型。\n",
    "1. 单个代码块运行时长应低于五分钟。\n",
    "1. 禁止使用任何开源的代码(例如，你在GitHub上找到的决策树的实现)。\n",
    "\n",
    "## 数据准备\n",
    "项目数据保存在：work/data/ 目录下。\n",
    "\n",
    "## 环境配置/安装\n",
    "无"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54257, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3018: DtypeWarning: Columns (0,1,3,4,6,17,18,19,30,36,38,39,40) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>age</td>\n",
       "      <td>class of worker</td>\n",
       "      <td>detailed industry recode</td>\n",
       "      <td>detailed occupation recode</td>\n",
       "      <td>education</td>\n",
       "      <td>wage per hour</td>\n",
       "      <td>enroll in edu inst last wk</td>\n",
       "      <td>marital stat</td>\n",
       "      <td>major industry code</td>\n",
       "      <td>...</td>\n",
       "      <td>country of birth father</td>\n",
       "      <td>country of birth mother</td>\n",
       "      <td>country of birth self</td>\n",
       "      <td>citizenship</td>\n",
       "      <td>own business or self employed</td>\n",
       "      <td>fill inc questionnaire for veteran's admin</td>\n",
       "      <td>veterans benefits</td>\n",
       "      <td>weeks worked in year</td>\n",
       "      <td>year</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>Private</td>\n",
       "      <td>34</td>\n",
       "      <td>26</td>\n",
       "      <td>Masters degree(MA MS MEng MEd MSW MBA)</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Finance insurance and real estate</td>\n",
       "      <td>...</td>\n",
       "      <td>China</td>\n",
       "      <td>China</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>Foreign born- Not a citizen of U S</td>\n",
       "      <td>2</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>95</td>\n",
       "      <td>50000+.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>Private</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Manufacturing-durable goods</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>95</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7th and 8th grade</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>...</td>\n",
       "      <td>Germany</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>Local government</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>Bachelors degree(BA AB BS)</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Education</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>95</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1                  2                         3   \\\n",
       "0  id  age    class of worker  detailed industry recode   \n",
       "1   0   33            Private                        34   \n",
       "2   1   63            Private                         7   \n",
       "3   2   71    Not in universe                         0   \n",
       "4   3   43   Local government                        43   \n",
       "\n",
       "                           4                                        5   \\\n",
       "0  detailed occupation recode                                education   \n",
       "1                          26   Masters degree(MA MS MEng MEd MSW MBA)   \n",
       "2                          22               Some college but no degree   \n",
       "3                           0                        7th and 8th grade   \n",
       "4                          10               Bachelors degree(BA AB BS)   \n",
       "\n",
       "              6                           7   \\\n",
       "0  wage per hour  enroll in edu inst last wk   \n",
       "1              0             Not in universe   \n",
       "2              0             Not in universe   \n",
       "3              0             Not in universe   \n",
       "4              0             Not in universe   \n",
       "\n",
       "                                 8                                   9   ...  \\\n",
       "0                      marital stat                 major industry code  ...   \n",
       "1   Married-civilian spouse present   Finance insurance and real estate  ...   \n",
       "2                     Never married         Manufacturing-durable goods  ...   \n",
       "3   Married-civilian spouse present         Not in universe or children  ...   \n",
       "4   Married-civilian spouse present                           Education  ...   \n",
       "\n",
       "                        32                       33                     34  \\\n",
       "0  country of birth father  country of birth mother  country of birth self   \n",
       "1                    China                    China                 Taiwan   \n",
       "2                        ?                        ?          United-States   \n",
       "3                  Germany            United-States          United-States   \n",
       "4            United-States            United-States          United-States   \n",
       "\n",
       "                                     35                             36  \\\n",
       "0                           citizenship  own business or self employed   \n",
       "1   Foreign born- Not a citizen of U S                               2   \n",
       "2     Native- Born in the United States                              0   \n",
       "3     Native- Born in the United States                              0   \n",
       "4     Native- Born in the United States                              0   \n",
       "\n",
       "                                           37                 38  \\\n",
       "0  fill inc questionnaire for veteran's admin  veterans benefits   \n",
       "1                             Not in universe                  2   \n",
       "2                             Not in universe                  2   \n",
       "3                             Not in universe                  2   \n",
       "4                             Not in universe                  2   \n",
       "\n",
       "                     39    40         41  \n",
       "0  weeks worked in year  year          y  \n",
       "1                    52    95    50000+.  \n",
       "2                    52    95   - 50000.  \n",
       "3                     0    95   - 50000.  \n",
       "4                    52    95   - 50000.  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('work/data/train.csv', header=None, encoding='big5')\r\n",
    "print(df.shape)\r\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3018: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,502,503,504,508) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54257, 511)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>501</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>age</td>\n",
       "      <td>Private</td>\n",
       "      <td>Self-employed-incorporated</td>\n",
       "      <td>State government</td>\n",
       "      <td>Self-employed-not incorporated</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Without pay</td>\n",
       "      <td>Federal government</td>\n",
       "      <td>Never worked</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>weeks worked in year</td>\n",
       "      <td>94</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 511 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  0    1         2                            3                  4    \\\n",
       "0  id  age   Private   Self-employed-incorporated   State government   \n",
       "1   0   33         1                            0                  0   \n",
       "2   1   63         1                            0                  0   \n",
       "3   2   71         0                            0                  0   \n",
       "4   3   43         0                            0                  0   \n",
       "\n",
       "                               5                 6             7    \\\n",
       "0   Self-employed-not incorporated   Not in universe   Without pay   \n",
       "1                                0                 0             0   \n",
       "2                                0                 0             0   \n",
       "3                                0                 1             0   \n",
       "4                                0                 0             0   \n",
       "\n",
       "                   8              9    ... 501               502   503  504  \\\n",
       "0   Federal government   Never worked  ...   1   Not in universe   Yes   No   \n",
       "1                    0              0  ...   0                 1     0    0   \n",
       "2                    0              0  ...   0                 1     0    0   \n",
       "3                    0              0  ...   0                 1     0    0   \n",
       "4                    0              0  ...   0                 1     0    0   \n",
       "\n",
       "   505  506  507                   508  509  510  \n",
       "0    2    0    1  weeks worked in year   94   95  \n",
       "1    1    0    0                    52    0    1  \n",
       "2    1    0    0                    52    0    1  \n",
       "3    1    0    0                     0    0    1  \n",
       "4    1    0    0                    52    0    1  \n",
       "\n",
       "[5 rows x 511 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('work/data/X_train', header=None, encoding='big5')\r\n",
    "print(df.shape)\r\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preparing Data\n",
    "对属性进行正则化，处理过后划分为训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 48830\n",
      "Size of eval set: 5426\n",
      "Size of testing set: 27622\n",
      "Dimension of data: 510\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\r\n",
    "X_train_fpath = 'work/data/X_train'\r\n",
    "Y_train_fpath = 'work/data/Y_train'\r\n",
    "X_test_fpath = 'work/data/X_test'\r\n",
    "output_fpath = 'work/output_{}.csv'\r\n",
    "\r\n",
    "# Parse csv files to numpy array\r\n",
    "with open(X_train_fpath) as f:\r\n",
    "    next(f)\r\n",
    "    X_train = np.array([line.strip('\\n').split(',')[1:] for line in f], dtype = float)\r\n",
    "with open(Y_train_fpath) as f:\r\n",
    "    next(f)\r\n",
    "    Y_train = np.array([line.strip('\\n').split(',')[1] for line in f], dtype = float)\r\n",
    "with open(X_test_fpath) as f:\r\n",
    "    next(f)\r\n",
    "    X_test = np.array([line.strip('\\n').split(',')[1:] for line in f], dtype = float)\r\n",
    "\r\n",
    "# 规范化\r\n",
    "def _normalize(X, train = True, specified_column = None, X_mean = None, X_std = None):\r\n",
    "    # This function normalizes specific columns of X.\r\n",
    "    # The mean and standard variance of training data will be reused when processing testing data.\r\n",
    "    #\r\n",
    "    # Arguments:\r\n",
    "    #     X: data to be processed\r\n",
    "    #     train: 'True' when processing training data, 'False' for testing data\r\n",
    "    #     specific_column: indexes of the columns that will be normalized. If 'None', all columns\r\n",
    "    #         will be normalized.\r\n",
    "    #     X_mean: mean value of training data, used when train = 'False'\r\n",
    "    #     X_std: standard deviation of training data, used when train = 'False'\r\n",
    "    # Outputs:\r\n",
    "    #     X: normalized data\r\n",
    "    #     X_mean: computed mean value of training data\r\n",
    "    #     X_std: computed standard deviation of training data\r\n",
    "\r\n",
    "    if specified_column == None:\r\n",
    "        specified_column = np.arange(X.shape[1])\r\n",
    "    if train:\r\n",
    "        X_mean = np.mean(X[:, specified_column] ,0).reshape(1, -1)\r\n",
    "        X_std  = np.std(X[:, specified_column], 0).reshape(1, -1)\r\n",
    "\r\n",
    "    X[:,specified_column] = (X[:, specified_column] - X_mean) / (X_std + 1e-8)\r\n",
    "     \r\n",
    "    return X, X_mean, X_std\r\n",
    "\r\n",
    "def _train_dev_split(X, Y, dev_ratio = 0.25):\r\n",
    "    # This function spilts data into training set and development set.\r\n",
    "    train_size = int(len(X) * (1 - dev_ratio))\r\n",
    "    return X[:train_size], Y[:train_size], X[train_size:], Y[train_size:]\r\n",
    "\r\n",
    "# Normalize training and testing data\r\n",
    "X_train, X_mean, X_std = _normalize(X_train, train = True)\r\n",
    "X_test, _, _ = _normalize(X_test, train = False, specified_column = None, X_mean = X_mean, X_std = X_std)\r\n",
    "    \r\n",
    "# Split data into training set and development set\r\n",
    "dev_ratio = 0.1\r\n",
    "# 9:1\r\n",
    "X_train, Y_train, X_eval, Y_eval = _train_dev_split(X_train, Y_train, dev_ratio = dev_ratio)\r\n",
    "\r\n",
    "train_size = X_train.shape[0]\r\n",
    "eval_size = X_eval.shape[0]\r\n",
    "test_size = X_test.shape[0]\r\n",
    "data_dim = X_train.shape[1]\r\n",
    "\r\n",
    "print('Size of training set: {}'.format(X_train.shape[0]))\r\n",
    "print('Size of eval set: {}'.format(X_eval.shape[0]))\r\n",
    "print('Size of testing set: {}'.format(X_test.shape[0]))\r\n",
    "print('Dimension of data: {}'.format(data_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Some Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _shuffle(X, Y):\r\n",
    "    # This function shuffles two equal-length list/array, X and Y, together.\r\n",
    "    randomize = np.arange(len(X))\r\n",
    "    np.random.shuffle(randomize)\r\n",
    "    return (X[randomize], Y[randomize])\r\n",
    "\r\n",
    "def _sigmoid(z):\r\n",
    "    # Sigmoid function can be used to calculate probability.\r\n",
    "    # To avoid overflow, minimum/maximum output value is set.\r\n",
    "    return np.clip(1 / (1.0 + np.exp(-z)), 1e-8, 1 - (1e-8))\r\n",
    "\r\n",
    "def _f(X, w, b):\r\n",
    "    # This is the logistic regression function, parameterized by w and b\r\n",
    "    #\r\n",
    "    # Arguements:\r\n",
    "    #     X: input data, shape = [batch_size, data_dimension]\r\n",
    "    #     w: weight vector, shape = [data_dimension, ]\r\n",
    "    #     b: bias, scalar\r\n",
    "    # Output:\r\n",
    "    #     predicted probability of each row of X being positively labeled, shape = [batch_size, ]\r\n",
    "    return _sigmoid(np.matmul(X, w) + b)\r\n",
    "\r\n",
    "def _predict(X, w, b):\r\n",
    "    # This function returns a truth value prediction for each row of X \r\n",
    "    # by rounding the result of logistic regression function.\r\n",
    "    return np.round(_f(X, w, b)).astype(np.int)\r\n",
    "    \r\n",
    "def _accuracy(Y_pred, Y_label):\r\n",
    "    # This function calculates prediction accuracy\r\n",
    "    acc = 1 - np.mean(np.abs(Y_pred - Y_label))\r\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Functions about gradient and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 交叉熵损失 if 0-1损失 第二项为0\r\n",
    "def _cross_entropy_loss(y_pred, Y_label):\r\n",
    "    # This function computes the cross entropy.\r\n",
    "    #\r\n",
    "    # Arguements:\r\n",
    "    #     y_pred: probabilistic predictions, float vector\r\n",
    "    #     Y_label: ground truth labels, bool vector\r\n",
    "    # Output:\r\n",
    "    #     cross entropy, scalar\r\n",
    "    cross_entropy = -np.dot(Y_label, np.log(y_pred)) - np.dot((1 - Y_label), np.log(1 - y_pred))\r\n",
    "    return cross_entropy\r\n",
    "\r\n",
    "# \r\n",
    "def _gradient(X, Y_label, w, b):\r\n",
    "    # This function computes the gradient of cross entropy loss with respect to weight w and bias b.\r\n",
    "    y_pred = _f(X, w, b)\r\n",
    "    pred_error = Y_label - y_pred\r\n",
    "    w_grad = -np.sum(pred_error * X.T, 1)\r\n",
    "    b_grad = -np.sum(pred_error)\r\n",
    "    return w_grad, b_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Trainning\n",
    "`Mini-batch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10, step 50/381 : train_loss = 1.347386236965906, train_acc = 0.8488224452181037, eval_loss = 1.400598892932686, eval_acc = 0.8518245484703281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:10: RuntimeWarning: overflow encountered in exp\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10, step 100/381 : train_loss = 0.9152016432029676, train_acc = 0.8617857874257628, eval_loss = 0.965991675211801, eval_acc = 0.8558791006266127\n",
      "Epoch 0/10, step 150/381 : train_loss = 0.7852583061703493, train_acc = 0.8539627278312513, eval_loss = 0.8467023409488244, eval_acc = 0.8497972723921858\n",
      "Epoch 0/10, step 200/381 : train_loss = 0.6855500080014343, train_acc = 0.8627687896784764, eval_loss = 0.7420444348505428, eval_acc = 0.8510873571691854\n",
      "Epoch 0/10, step 250/381 : train_loss = 0.6626799916718044, train_acc = 0.8518533688306369, eval_loss = 0.6843539759344478, eval_acc = 0.8462956137117582\n",
      "Epoch 0/10, step 300/381 : train_loss = 0.6722368835334585, train_acc = 0.850419823878763, eval_loss = 0.7212556694191992, eval_acc = 0.8431625506819019\n",
      "Epoch 0/10, step 350/381 : train_loss = 0.5415013375184299, train_acc = 0.8645095228343231, eval_loss = 0.5956548816527707, eval_acc = 0.8534832288978991\n",
      "Epoch 0/10, step 380/381 : train_loss = 0.5476793641705842, train_acc = 0.8615605160761827, eval_loss = 0.5971872765737423, eval_acc = 0.8573534832288979\n",
      "Epoch 1/10, step 50/381 : train_loss = 0.520197120568741, train_acc = 0.8530821216465287, eval_loss = 0.5756371351198375, eval_acc = 0.8475856984887579\n",
      "Epoch 1/10, step 100/381 : train_loss = 0.4683572388702472, train_acc = 0.8602498464058981, eval_loss = 0.5151070012119039, eval_acc = 0.8496129745669001\n",
      "Epoch 1/10, step 150/381 : train_loss = 0.44626484885429574, train_acc = 0.8692607003891051, eval_loss = 0.4765391936828192, eval_acc = 0.8650939918908958\n",
      "Epoch 1/10, step 200/381 : train_loss = 0.46375217192688756, train_acc = 0.8594921155027647, eval_loss = 0.5209083007160215, eval_acc = 0.852930335422042\n",
      "Epoch 1/10, step 250/381 : train_loss = 0.4494819665359848, train_acc = 0.8585910301044439, eval_loss = 0.4937525184406186, eval_acc = 0.8516402506450425\n",
      "Epoch 1/10, step 300/381 : train_loss = 0.42552905318999246, train_acc = 0.8556010649191071, eval_loss = 0.45717340275441076, eval_acc = 0.8514559528197567\n",
      "Epoch 1/10, step 350/381 : train_loss = 0.42113694236968163, train_acc = 0.8607823059594512, eval_loss = 0.46348429781456685, eval_acc = 0.852930335422042\n",
      "Epoch 1/10, step 380/381 : train_loss = 0.39904321655303177, train_acc = 0.8648986278926889, eval_loss = 0.4248971078552518, eval_acc = 0.86490969406561\n",
      "Epoch 2/10, step 50/381 : train_loss = 0.4346224720366914, train_acc = 0.8548023755887774, eval_loss = 0.4609538098915485, eval_acc = 0.8485071876151862\n",
      "Epoch 2/10, step 100/381 : train_loss = 0.3923956025090415, train_acc = 0.8670079868933033, eval_loss = 0.42413396929246294, eval_acc = 0.8586435680058975\n",
      "Epoch 2/10, step 150/381 : train_loss = 0.3995503389795209, train_acc = 0.8609870980954332, eval_loss = 0.4451562989979174, eval_acc = 0.8499815702174714\n",
      "Epoch 2/10, step 200/381 : train_loss = 0.3899945539693655, train_acc = 0.8572803604341593, eval_loss = 0.43982862908042286, eval_acc = 0.8440840398083302\n",
      "Epoch 2/10, step 250/381 : train_loss = 0.3593450339469139, train_acc = 0.8709809543313537, eval_loss = 0.40433358814068665, eval_acc = 0.8604865462587541\n",
      "Epoch 2/10, step 300/381 : train_loss = 0.3748111111601529, train_acc = 0.8675199672332583, eval_loss = 0.4196960003401859, eval_acc = 0.8617766310357537\n",
      "Epoch 2/10, step 350/381 : train_loss = 0.3703513254990469, train_acc = 0.8669260700389105, eval_loss = 0.41804964042741555, eval_acc = 0.8520088462956137\n",
      "Epoch 2/10, step 380/381 : train_loss = 0.36328355503504767, train_acc = 0.8688306369035429, eval_loss = 0.395140184186746, eval_acc = 0.8608551419093254\n",
      "Epoch 3/10, step 50/381 : train_loss = 0.3667617885217751, train_acc = 0.8671308621748925, eval_loss = 0.40048983606743443, eval_acc = 0.8604865462587541\n",
      "Epoch 3/10, step 100/381 : train_loss = 0.35360533975074676, train_acc = 0.8685644071267663, eval_loss = 0.39086426288977333, eval_acc = 0.8650939918908958\n",
      "Epoch 3/10, step 150/381 : train_loss = 0.35412973445213575, train_acc = 0.8656563587958223, eval_loss = 0.39303244637743845, eval_acc = 0.8584592701806119\n",
      "Epoch 3/10, step 200/381 : train_loss = 0.3590742324953709, train_acc = 0.8645709604751177, eval_loss = 0.3944381871174818, eval_acc = 0.8617766310357537\n",
      "Epoch 3/10, step 250/381 : train_loss = 0.3664068327141785, train_acc = 0.8649805447470817, eval_loss = 0.4009416310136879, eval_acc = 0.854036122373756\n",
      "Epoch 3/10, step 300/381 : train_loss = 0.35723431597516137, train_acc = 0.8696498054474708, eval_loss = 0.39744904200659437, eval_acc = 0.8569848875783266\n",
      "Epoch 3/10, step 350/381 : train_loss = 0.3524748289033771, train_acc = 0.8708785582633627, eval_loss = 0.3854558575255915, eval_acc = 0.8625138223368964\n",
      "Epoch 3/10, step 380/381 : train_loss = 0.3590500094054613, train_acc = 0.8656768380094204, eval_loss = 0.38422321854508834, eval_acc = 0.8617766310357537\n",
      "Epoch 4/10, step 50/381 : train_loss = 0.36264869668435873, train_acc = 0.8653286913782511, eval_loss = 0.39855663300624034, eval_acc = 0.85514190932547\n",
      "Epoch 4/10, step 100/381 : train_loss = 0.3604975080000873, train_acc = 0.8658816301454024, eval_loss = 0.4105462641088316, eval_acc = 0.8553262071507556\n",
      "Epoch 4/10, step 150/381 : train_loss = 0.3564967782256114, train_acc = 0.8667007986893304, eval_loss = 0.39057223845742817, eval_acc = 0.8595650571323259\n",
      "Epoch 4/10, step 200/381 : train_loss = 0.3527179993831093, train_acc = 0.8693630964570961, eval_loss = 0.3858817452121384, eval_acc = 0.8647253962403243\n",
      "Epoch 4/10, step 250/381 : train_loss = 0.36648828966601643, train_acc = 0.8644480851935286, eval_loss = 0.41029858763804716, eval_acc = 0.8568005897530409\n",
      "Epoch 4/10, step 300/381 : train_loss = 0.351422769480477, train_acc = 0.8657177964366168, eval_loss = 0.39303785532877383, eval_acc = 0.8590121636564688\n",
      "Epoch 4/10, step 350/381 : train_loss = 0.3687938519023856, train_acc = 0.8581609666188819, eval_loss = 0.40015912716296487, eval_acc = 0.8569848875783266\n",
      "Epoch 4/10, step 380/381 : train_loss = 0.3420811103956837, train_acc = 0.8683800942043826, eval_loss = 0.3751930193928467, eval_acc = 0.8579063767047549\n",
      "Epoch 5/10, step 50/381 : train_loss = 0.3302270800745182, train_acc = 0.8689944706123285, eval_loss = 0.36852577788742297, eval_acc = 0.8556948028013269\n",
      "Epoch 5/10, step 100/381 : train_loss = 0.34052478475076675, train_acc = 0.8683800942043826, eval_loss = 0.37442216550948215, eval_acc = 0.8612237375598968\n",
      "Epoch 5/10, step 150/381 : train_loss = 0.3405981277637372, train_acc = 0.8697522015154618, eval_loss = 0.3723756076252314, eval_acc = 0.8641725027644673\n",
      "Epoch 5/10, step 200/381 : train_loss = 0.3474172130238929, train_acc = 0.8686463239811592, eval_loss = 0.3986964140186972, eval_acc = 0.867121267969038\n",
      "Epoch 5/10, step 250/381 : train_loss = 0.340855490401304, train_acc = 0.8665369649805448, eval_loss = 0.3879554496988832, eval_acc = 0.8573534832288979\n",
      "Epoch 5/10, step 300/381 : train_loss = 0.33366211362426634, train_acc = 0.8697112430882654, eval_loss = 0.36908480221109613, eval_acc = 0.8638039071138961\n",
      "Epoch 5/10, step 350/381 : train_loss = 0.32117517430525355, train_acc = 0.8744009830022528, eval_loss = 0.3645435168908827, eval_acc = 0.8623295245116107\n",
      "Epoch 5/10, step 380/381 : train_loss = 0.33272551587770516, train_acc = 0.8721073110792545, eval_loss = 0.361574603657775, eval_acc = 0.8647253962403243\n",
      "Epoch 6/10, step 50/381 : train_loss = 0.3456555960901342, train_acc = 0.8687077616219537, eval_loss = 0.374727342928016, eval_acc = 0.8580906745300405\n",
      "Epoch 6/10, step 100/381 : train_loss = 0.32195130178615045, train_acc = 0.873499897603932, eval_loss = 0.3622769702037688, eval_acc = 0.8658311831920383\n",
      "Epoch 6/10, step 150/381 : train_loss = 0.3388200696217158, train_acc = 0.8667007986893304, eval_loss = 0.37159536068205357, eval_acc = 0.8588278658311832\n",
      "Epoch 6/10, step 200/381 : train_loss = 0.3238163382581627, train_acc = 0.8731517509727627, eval_loss = 0.35688837110036886, eval_acc = 0.8614080353851825\n",
      "Epoch 6/10, step 250/381 : train_loss = 0.32691372511044997, train_acc = 0.8699569936514437, eval_loss = 0.3591479516184065, eval_acc = 0.8636196092886104\n",
      "Epoch 6/10, step 300/381 : train_loss = 0.32754231352360025, train_acc = 0.8680524267868114, eval_loss = 0.3682663327740257, eval_acc = 0.8603022484334685\n",
      "Epoch 6/10, step 350/381 : train_loss = 0.3258001611755046, train_acc = 0.8682367397091951, eval_loss = 0.3677240242315396, eval_acc = 0.8579063767047549\n",
      "Epoch 6/10, step 380/381 : train_loss = 0.32816830642216066, train_acc = 0.8693835756706942, eval_loss = 0.36171645748448766, eval_acc = 0.867121267969038\n",
      "Epoch 7/10, step 50/381 : train_loss = 0.3175343573623028, train_acc = 0.873499897603932, eval_loss = 0.356350794456304, eval_acc = 0.8691485440471802\n",
      "Epoch 7/10, step 100/381 : train_loss = 0.3220009954877125, train_acc = 0.8744419414294491, eval_loss = 0.358727432415702, eval_acc = 0.8634353114633248\n",
      "Epoch 7/10, step 150/381 : train_loss = 0.3305955213903524, train_acc = 0.8686668031947573, eval_loss = 0.35746500804141423, eval_acc = 0.8591964614817545\n",
      "Epoch 7/10, step 200/381 : train_loss = 0.32302814029642124, train_acc = 0.872250665574442, eval_loss = 0.36488833884672156, eval_acc = 0.8625138223368964\n",
      "Epoch 7/10, step 250/381 : train_loss = 0.32025796652922844, train_acc = 0.8705304116321934, eval_loss = 0.36008253698973786, eval_acc = 0.8625138223368964\n",
      "Epoch 7/10, step 300/381 : train_loss = 0.3219910089368282, train_acc = 0.8729674380503789, eval_loss = 0.34953452123180245, eval_acc = 0.8656468853667527\n",
      "Epoch 7/10, step 350/381 : train_loss = 0.3208580070705966, train_acc = 0.8721073110792545, eval_loss = 0.35206761035830214, eval_acc = 0.8643568005897531\n",
      "Epoch 7/10, step 380/381 : train_loss = 0.31430803053171624, train_acc = 0.8733565431087447, eval_loss = 0.3442739956568529, eval_acc = 0.8656468853667527\n",
      "Epoch 8/10, step 50/381 : train_loss = 0.3314301109448099, train_acc = 0.8662912144173663, eval_loss = 0.3676573957819751, eval_acc = 0.8625138223368964\n",
      "Epoch 8/10, step 100/381 : train_loss = 0.3255758437986244, train_acc = 0.868216260495597, eval_loss = 0.35753417552492195, eval_acc = 0.8571691854036122\n",
      "Epoch 8/10, step 150/381 : train_loss = 0.31674989040755525, train_acc = 0.8749948801966004, eval_loss = 0.3516086430321963, eval_acc = 0.8614080353851825\n",
      "Epoch 8/10, step 200/381 : train_loss = 0.3169229965409289, train_acc = 0.8708785582633627, eval_loss = 0.34929559101057905, eval_acc = 0.866015481017324\n",
      "Epoch 8/10, step 250/381 : train_loss = 0.3125736564369679, train_acc = 0.8729879172639771, eval_loss = 0.3558988059234633, eval_acc = 0.8601179506081829\n",
      "Epoch 8/10, step 300/381 : train_loss = 0.32465507233694585, train_acc = 0.8700593897194348, eval_loss = 0.35194439521460325, eval_acc = 0.8643568005897531\n",
      "Epoch 8/10, step 350/381 : train_loss = 0.321653732112893, train_acc = 0.8695064509522834, eval_loss = 0.3536633993686226, eval_acc = 0.8614080353851825\n",
      "Epoch 8/10, step 380/381 : train_loss = 0.3102755524934392, train_acc = 0.8753225476141716, eval_loss = 0.3415885759753436, eval_acc = 0.8687799483966089\n",
      "Epoch 9/10, step 50/381 : train_loss = 0.3220828398108354, train_acc = 0.8705099324185951, eval_loss = 0.3526815872306161, eval_acc = 0.8604865462587541\n",
      "Epoch 9/10, step 100/381 : train_loss = 0.31449065997699305, train_acc = 0.875158713905386, eval_loss = 0.35772978090131086, eval_acc = 0.866015481017324\n",
      "Epoch 9/10, step 150/381 : train_loss = 0.3141249146891724, train_acc = 0.8734589391767356, eval_loss = 0.3482849607567331, eval_acc = 0.8678584592701806\n",
      "Epoch 9/10, step 200/381 : train_loss = 0.31630341261673267, train_acc = 0.8709809543313537, eval_loss = 0.3457003170478517, eval_acc = 0.8663840766678953\n",
      "Epoch 9/10, step 250/381 : train_loss = 0.3165078699037002, train_acc = 0.8719844357976654, eval_loss = 0.3381895066522098, eval_acc = 0.8691485440471802\n",
      "Epoch 9/10, step 300/381 : train_loss = 0.3211023733500236, train_acc = 0.868851116117141, eval_loss = 0.3509102642777991, eval_acc = 0.8599336527828971\n",
      "Epoch 9/10, step 350/381 : train_loss = 0.3133905152466426, train_acc = 0.8736842105263158, eval_loss = 0.33751488580315897, eval_acc = 0.8650939918908958\n",
      "Epoch 9/10, step 380/381 : train_loss = 0.314415715887756, train_acc = 0.8699160352242474, eval_loss = 0.34212073630604034, eval_acc = 0.8632510136380391\n",
      "Training loss: 0.31723862821153564\n",
      "Eval loss: 0.34562381603010406\n",
      "Training accuracy: 0.8690559082531231\n",
      "Eval accuracy: 0.8626981201621821\n"
     ]
    }
   ],
   "source": [
    "# Zero initialization for weights ans bias\r\n",
    "w = np.zeros((data_dim, )) \r\n",
    "b = np.zeros((1,))\r\n",
    "\r\n",
    "# Some parameters for training    \r\n",
    "EPOCH = 10\r\n",
    "batch_size = 128\r\n",
    "learning_rate = 0.2\r\n",
    "\r\n",
    "# Keep the loss and accuracy at every iteration for plotting\r\n",
    "train_loss = []\r\n",
    "eval_loss = []\r\n",
    "train_acc = []\r\n",
    "eval_acc = []\r\n",
    "\r\n",
    "# Calcuate the number of parameter updates\r\n",
    "adagrad_step = 1\r\n",
    "batch_step = 0\r\n",
    "# Iterative training\r\n",
    "for epoch in range(EPOCH):\r\n",
    "    # Random shuffle at the begging of each epoch\r\n",
    "    X_train, Y_train = _shuffle(X_train, Y_train)\r\n",
    "        \r\n",
    "    # Mini-batch training\r\n",
    "    step = 0\r\n",
    "    steps = int(np.floor(train_size / batch_size))\r\n",
    "    for idx in range(steps):  # floor(48830/128)=382\r\n",
    "        X = X_train[idx*batch_size:(idx+1)*batch_size]\r\n",
    "        Y = Y_train[idx*batch_size:(idx+1)*batch_size]\r\n",
    "\r\n",
    "        # Compute the gradient\r\n",
    "        w_grad, b_grad = _gradient(X, Y, w, b)\r\n",
    "            \r\n",
    "        # gradient descent update\r\n",
    "        # learning rate decay with time\r\n",
    "        w = w - learning_rate/np.sqrt(adagrad_step) * w_grad\r\n",
    "        b = b - learning_rate/np.sqrt(adagrad_step) * b_grad\r\n",
    "        \r\n",
    "        step += 1\r\n",
    "        adagrad_step += 1\r\n",
    "\r\n",
    "        # Compute loss and accuracy of training set and development set\r\n",
    "        y_train_pred = _f(X_train, w, b)\r\n",
    "        Y_train_pred = np.round(y_train_pred)\r\n",
    "        y_eval_pred = _f(X_eval, w, b)\r\n",
    "        Y_eval_pred = np.round(y_eval_pred)\r\n",
    "\r\n",
    "        acc_train = _accuracy(Y_train_pred, Y_train)\r\n",
    "        loss_train = _cross_entropy_loss(y_train_pred, Y_train) / train_size\r\n",
    "        acc_eval = _accuracy(Y_eval_pred, Y_eval)\r\n",
    "        loss_eval = _cross_entropy_loss(y_eval_pred, Y_eval) / eval_size\r\n",
    "\r\n",
    "        if step % 50 == 0 or step == steps:\r\n",
    "            print(f'Epoch {epoch}/{EPOCH}, step {step}/{steps} : train_loss = {loss_train}, train_acc = {acc_train}, eval_loss = {loss_eval}, eval_acc = {acc_eval}')\r\n",
    "\r\n",
    "        train_acc.append(acc_train)\r\n",
    "        train_loss.append(loss_train)\r\n",
    "        eval_acc.append(acc_eval)\r\n",
    "        eval_loss.append(loss_eval)\r\n",
    "\r\n",
    "print('Training loss: {}'.format(train_loss[-1]))\r\n",
    "print('Eval loss: {}'.format(eval_loss[-1]))\r\n",
    "print('Training accuracy: {}'.format(train_acc[-1]))\r\n",
    "print('Eval accuracy: {}'.format(eval_acc[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plotting Loss and accuracy curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss curve\r\n",
    "# plt.figure(figsize=(16, 8))\r\n",
    "plt.plot(train_loss)\r\n",
    "plt.plot(eval_loss)\r\n",
    "plt.title('Loss')\r\n",
    "plt.legend(['train', 'eval'])\r\n",
    "plt.savefig('loss.png')\r\n",
    "plt.show()\r\n",
    "\r\n",
    "# Accuracy curve\r\n",
    "# plt.figure(figsize=(16, 8))\r\n",
    "plt.plot(train_acc)\r\n",
    "plt.plot(eval_acc)\r\n",
    "plt.title('Accuracy')\r\n",
    "plt.legend(['train', 'eval'])\r\n",
    "plt.savefig('acc.png')\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Predicting testing labels\n",
    "输出到`output_logistic.csv`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Local government -5.370818305378536\n",
      " Other Rel 18+ ever marr RP of subfamily -4.303398837549008\n",
      "num persons worked for employer 4.177335768723998\n",
      " Neither parent present -3.8146477310419447\n",
      "dividends from stocks -3.6462348599573593\n",
      " 2 -3.492485219117511\n",
      " High school graduate -3.486094628398619\n",
      " Child under 18 ever married -3.405443955741911\n",
      " Grandchild 18+ never marr RP of subfamily -3.331278619262018\n",
      " Philippines -3.304985181079396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:10: RuntimeWarning: overflow encountered in exp\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Predict testing labels\r\n",
    "predictions = _predict(X_test, w, b)\r\n",
    "with open(output_fpath.format('logistic'), 'w') as f:\r\n",
    "    f.write('id,label\\n')\r\n",
    "    for i, label in  enumerate(predictions):\r\n",
    "        f.write('{},{}\\n'.format(i, label))\r\n",
    "\r\n",
    "# Print out the most significant weights\r\n",
    "ind = np.argsort(np.abs(w))[::-1]\r\n",
    "with open(X_test_fpath) as f:\r\n",
    "    content = f.readline().strip('\\n').split(',')\r\n",
    "features = np.array(content)\r\n",
    "for i in ind[0:10]:\r\n",
    "    print(features[i], w[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Porbabilistic generative model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preparing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parse csv files to numpy array\r\n",
    "with open(X_train_fpath) as f:\r\n",
    "    next(f)\r\n",
    "    X_train = np.array([line.strip('\\n').split(',')[1:] for line in f], dtype = float)\r\n",
    "with open(Y_train_fpath) as f:\r\n",
    "    next(f)\r\n",
    "    Y_train = np.array([line.strip('\\n').split(',')[1] for line in f], dtype = float)\r\n",
    "with open(X_test_fpath) as f:\r\n",
    "    next(f)\r\n",
    "    X_test = np.array([line.strip('\\n').split(',')[1:] for line in f], dtype = float)\r\n",
    "\r\n",
    "# Normalize training and testing data\r\n",
    "X_train, X_mean, X_std = _normalize(X_train, train = True)\r\n",
    "X_test, _, _= _normalize(X_test, train = False, specified_column = None, X_mean = X_mean, X_std = X_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Mean and Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute in-class mean\r\n",
    "X_train_0 = np.array([x for x, y in zip(X_train, Y_train) if y == 0])\r\n",
    "X_train_1 = np.array([x for x, y in zip(X_train, Y_train) if y == 1])\r\n",
    "\r\n",
    "mean_0 = np.mean(X_train_0, axis = 0)\r\n",
    "mean_1 = np.mean(X_train_1, axis = 0)  \r\n",
    "\r\n",
    "# Compute in-class covariance\r\n",
    "cov_0 = np.zeros((data_dim, data_dim))\r\n",
    "cov_1 = np.zeros((data_dim, data_dim))\r\n",
    "\r\n",
    "for x in X_train_0:\r\n",
    "    cov_0 += np.dot(np.transpose([x - mean_0]), [x - mean_0]) / X_train_0.shape[0]\r\n",
    "for x in X_train_1:\r\n",
    "    cov_1 += np.dot(np.transpose([x - mean_1]), [x - mean_1]) / X_train_1.shape[0]\r\n",
    "\r\n",
    "# Shared covariance is taken as a weighted average of individual in-class covariance.\r\n",
    "cov = (cov_0 * X_train_0.shape[0] + cov_1 * X_train_1.shape[0]) / (X_train_0.shape[0] + X_train_1.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Computing weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8700420230020642\n"
     ]
    }
   ],
   "source": [
    "# Compute inverse of covariance matrix.\r\n",
    "# Since covariance matrix may be nearly singular, np.linalg.inv() may give a large numerical error.\r\n",
    "# Via SVD decomposition, one can get matrix inverse efficiently and accurately.\r\n",
    "u, s, v = np.linalg.svd(cov, full_matrices=False)\r\n",
    "inv = np.matmul(v.T * 1 / s, u.T)\r\n",
    "\r\n",
    "# Directly compute weights and bias\r\n",
    "w = np.dot(inv, mean_0 - mean_1)\r\n",
    "b =  (-0.5) * np.dot(mean_0, np.dot(inv, mean_0)) + 0.5 * np.dot(mean_1, np.dot(inv, mean_1))\\\r\n",
    "    + np.log(float(X_train_0.shape[0]) / X_train_1.shape[0]) \r\n",
    "\r\n",
    "# Compute accuracy on training set\r\n",
    "Y_train_pred = 1 - _predict(X_train, w, b)\r\n",
    "print('Training accuracy: {}'.format(_accuracy(Y_train_pred, Y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Predicting testing labels\n",
    "Predictions are saved to `output_generative.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retail trade 7.166015625\n",
      " 34 -5.45166015625\n",
      " 37 -5.06494140625\n",
      " Other service -4.76123046875\n",
      " 29 4.462890625\n",
      " Forestry and fisheries -4.35546875\n",
      " Public administration -3.927734375\n",
      " 28 3.796875\n",
      " 40 -3.7880859375\n",
      " Abroad 3.59765625\n"
     ]
    }
   ],
   "source": [
    "# Predict testing labels\r\n",
    "predictions = 1 - _predict(X_test, w, b)\r\n",
    "with open(output_fpath.format('generative'), 'w') as f:\r\n",
    "    f.write('id,label\\n')\r\n",
    "    for i, label in  enumerate(predictions):\r\n",
    "        f.write('{},{}\\n'.format(i, label))\r\n",
    "\r\n",
    "# Print out the most significant weights\r\n",
    "ind = np.argsort(np.abs(w))[::-1]\r\n",
    "with open(X_test_fpath) as f:\r\n",
    "    content = f.readline().strip('\\n').split(',')\r\n",
    "features = np.array(content)\r\n",
    "for i in ind[0:10]:\r\n",
    "    print(features[i], w[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
